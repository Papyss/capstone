{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries, functions, and globals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas.io.json import json_normalize\n",
    "from itertools import chain\n",
    "\n",
    "calc_field_count = 0\n",
    "\n",
    "host = \"localhost\"\n",
    "un = \"root\"\n",
    "pw=\"\"\n",
    "db_name = \"yelp\"\n",
    "\n",
    "fp = \"C:/Users/Tolis/Documents/Data Analytics Cource/CKME136 X10/Project/data/final/profiles\"\n",
    "fn = \"business_profiles\"\n",
    "\n",
    "\n",
    "def mysql_result_to_df(result, cursor):\n",
    "    field_names = [i[0] for i in mycursor.description]\n",
    "    return pd.DataFrame(myresult, columns=field_names)\n",
    "\n",
    "def flatten_json(y):\n",
    "    \"\"\"\n",
    "    Converts complex/nested JSON to table format.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "def df_to_csv(df, fp, ext=\".csv\", na_rep=\"\"):\n",
    "    try:\n",
    "        df.to_csv(fp + ext, encoding=\"utf-8\", header = True,\\\n",
    "            doublequote = True, sep=\",\", index=False, na_rep=na_rep)\n",
    "    except Exception as e:\n",
    "        print(\"Error: {}\".format(str(e)))\n",
    "        \n",
    "\"\"\"\n",
    "    The functions below are used to transform yelp json object literals\n",
    "    to a usable value such as a count, or a boolean True/False.\n",
    "\"\"\"\n",
    "\n",
    "def yelp_json_list_format(ylist):\n",
    "    result = (str(ylist).replace(\"'\", \"\\\"\"))\n",
    "    result = (result.replace(\"True\", \"\\\"True\\\"\"))\n",
    "    result = (result.replace(\"False\", \"\\\"False\\\"\"))\n",
    "    return result\n",
    "    \n",
    "def get_yelp_list_keys(val):\n",
    "    \"\"\"\n",
    "    Returns keys from a obj lit if their values evaluate to True.\n",
    "    \"\"\"\n",
    "\n",
    "    result = yelp_json_list_format(val)\n",
    "    true_keys = []\n",
    "    try:\n",
    "        result = json.loads(result)\n",
    "        \n",
    "        for k,v in result.items():   \n",
    "            if(v != \"\" and v!=False and v!=\"False\"): \n",
    "                true_keys.append(k)\n",
    "        return true_keys\n",
    "    except:\n",
    "        return float('nan')\n",
    "    \n",
    "def yelp_str_to_list(val):\n",
    "    \"\"\"\n",
    "    Splits a comma sep. string to list and returns it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = val.split(\", \")\n",
    "        for i,v in enumerate(result):\n",
    "            result[i] = result[i].strip().lower()\n",
    "            result[i] = re.sub(r\"\\s+\",\"-\", result[i])\n",
    "            result[i] = re.sub(r\"&\",\"and\", result[i])\n",
    "        return result\n",
    "    except:\n",
    "        return float('nan')\n",
    "    \n",
    "def get_yelp_loc(row):\n",
    "    city = row[\"city\"]\n",
    "    city = re.sub(r\"\\s+\",\"-\", city)\n",
    "    return [city.lower() + \"-\" + row[\"state\"].lower()]\n",
    "    \n",
    "def flatten_list(l):\n",
    "    return list(chain.from_iterable(l))\n",
    "\n",
    "def normalize_text(x):\n",
    "    result = str(x)\n",
    "    result = re.sub(r\"[\\[\\]\\\"\\n,'\\\\]\", \"\", result)\n",
    "    result = re.sub(r\"\\s{2,}\", \" \", result)\n",
    "    result = result.lower().strip()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load business table and flatten attributes field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to mysql and create df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192609 entries, 0 to 192608\n",
      "Data columns (total 14 columns):\n",
      "business_id     192609 non-null object\n",
      "name            192609 non-null object\n",
      "address         192609 non-null object\n",
      "city            192609 non-null object\n",
      "state           192609 non-null object\n",
      "postal_code     192609 non-null object\n",
      "latitude        192609 non-null float64\n",
      "longitude       192609 non-null float64\n",
      "stars           192609 non-null float64\n",
      "review_count    192609 non-null int64\n",
      "is_open         192609 non-null int64\n",
      "attributes      192609 non-null object\n",
      "categories      192609 non-null object\n",
      "hours           192609 non-null object\n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 20.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "  host=host,\n",
    "  user=un,\n",
    "  passwd=pw,\n",
    "  database=db_name\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "mycursor.execute(\"SELECT * FROM business\")\n",
    "\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "business_df = mysql_result_to_df(myresult, mycursor)\n",
    "\n",
    "#Stars gets imported as a string, so convert to decimal\n",
    "business_df[\"stars\"] = business_df[\"stars\"].apply(lambda val: float(val))\n",
    "\n",
    "print(business_df.info())\n",
    "\n",
    "mycursor.close()\n",
    "mydb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten and transform fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed: BusinessParking, GoodForMeal, Music, BestNights, Ambience, DietaryRestrictions, HairSpecializesIn\n"
     ]
    }
   ],
   "source": [
    "business_attributes = business_df[\"attributes\"]\n",
    "business_attributes_json = []\n",
    "\n",
    "for r in business_attributes:\n",
    "    r_json = json.loads(r)\n",
    "    business_attributes_json.append(r_json)\n",
    "\n",
    "business_attr_flat = json_normalize(business_attributes_json)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Declare calculated fields for json object literal provided by yelp.\n",
    "These object literals contain multiple keys that map to boolean values (for the most part). \n",
    "\n",
    "Example:\n",
    "\n",
    "Field: BusinessParking\n",
    "Value: \"{'garage': True, 'street': False, 'validated': False, 'lot': True, 'valet': False}\"\n",
    "\n",
    "Transforming these objects to a list of categores, a single number (count), or a boolen field makes them easier to analyze.\n",
    "Example Transfromation of BusinessParking using count:\n",
    "\n",
    "Field: BusinessParking_Count\n",
    "value: 2 (count all True values)\n",
    "\"\"\"\n",
    "\n",
    "business_attr_flat[\"CALC_BusinessParking_Options\"] = business_attr_flat[\"BusinessParking\"].apply(get_yelp_list_keys)\n",
    "business_attr_flat[\"CALC_GoodForMeal_Options\"] = business_attr_flat[\"GoodForMeal\"].apply(get_yelp_list_keys)\n",
    "business_attr_flat[\"CALC_Music_Options\"] = business_attr_flat[\"Music\"].apply(get_yelp_list_keys)\n",
    "business_attr_flat[\"CALC_BestNights_Options\"] = business_attr_flat[\"BestNights\"].apply(get_yelp_list_keys)\n",
    "business_attr_flat[\"CALC_Ambience_Options\"] = business_attr_flat[\"Ambience\"].apply(get_yelp_list_keys)\n",
    "business_attr_flat[\"CALC_DietaryRestrictions_Options\"] = business_attr_flat[\"DietaryRestrictions\"].apply(get_yelp_list_keys)\n",
    "business_attr_flat[\"CALC_HairSpecializesIn_Options\"] = business_attr_flat[\"HairSpecializesIn\"].apply(get_yelp_list_keys)\n",
    "\n",
    "\n",
    "transformed_fields = [\"BusinessParking\", \n",
    "                      \"GoodForMeal\",\n",
    "                      \"Music\",\n",
    "                      \"BestNights\",\n",
    "                      \"Ambience\",\n",
    "                      \"DietaryRestrictions\",\n",
    "                      \"HairSpecializesIn\"]\n",
    "\n",
    "calculated_fields = [\"CALC_BusinessParking_Options\",\n",
    "                   \"CALC_GoodForMeal_Options\",\n",
    "                   \"CALC_Music_Options\",\n",
    "                   \"CALC_BestNights_Options\",\n",
    "                   \"CALC_Ambience_Options\",\n",
    "                   \"CALC_DietaryRestrictions_Options\",\n",
    "                   \"CALC_HairSpecializesIn_Options\"]\n",
    "\n",
    "\n",
    "print(\"Transformed:\",\", \".join(transformed_fields))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop fields that have been transformed and concat with original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_attr_flat = business_attr_flat.drop(transformed_fields, axis=1)\n",
    "\n",
    "\n",
    "business_df = pd.concat([business_df,business_attr_flat], axis=1)\n",
    "\n",
    "#Create calculate field here instead of above to keep it at the end of the dataframe\n",
    "business_df[\"CALC_DaysOpen\"] = business_df[\"hours\"].apply(get_yelp_list_keys)\n",
    "business_df[\"CALC_Categories\"] = business_df[\"categories\"].apply(yelp_str_to_list)\n",
    "business_df[\"CALC_Location\"] = business_df.apply(get_yelp_loc, axis=1)\n",
    "\n",
    "calculated_fields.append(\"CALC_DaysOpen\")\n",
    "calculated_fields.append(\"CALC_Categories\")\n",
    "calculated_fields.append(\"CALC_Location\")\n",
    "\n",
    "business_df = business_df.drop([\"hours\"], axis=1)\n",
    "business_df = business_df.drop([\"attributes\"], axis=1)\n",
    "business_df = business_df.drop([\"categories\"], axis=1)\n",
    "\n",
    "#All things consisdered as possible nulls converted to actual nulls\n",
    "business_df = business_df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "business_df = business_df.replace(r'^{}*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten fields that contain list elements to obtain them as features for the binary matrix\n",
    "### These fields have been prefixed with 'CALC_' and are calculated fields that convert json objects to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lot', 'garage', 'valet', 'street', 'validated', 'lunch', 'dinner', 'brunch', 'breakfast', 'dessert']\n"
     ]
    }
   ],
   "source": [
    "# The binary matrix will contain a column for each unique feature found.\n",
    "# The rows will represent businesses, and each cell will be 1/0 indicating if that business has this feature.\n",
    "\n",
    "\n",
    "\n",
    "# Obtain new df of just the calculated fields from the bussiness df\n",
    "calc_field_count = len(calculated_fields)\n",
    "calc_fields = list(business_df.columns)\n",
    "calc_fields = calc_fields[-calc_field_count:]\n",
    "df_calc_fields = business_df[calc_fields]\n",
    "\n",
    "# Stores all unique values found in calculated columns\n",
    "bin_cols = []\n",
    "\n",
    "# Stores a mapping table that assists in the logic for the creation of the binary matrix\n",
    "field_map = []\n",
    "\n",
    "# Loop through each calculated column\n",
    "for name, values in df_calc_fields.iteritems():\n",
    "    \n",
    "    # Remove null rows from calc column since they are not needed for the bin matrix\n",
    "    reduced = pd.Series(values)\n",
    "    no_nulls = reduced.notnull()\n",
    "    reduced = reduced[no_nulls]\n",
    "    \n",
    "    # Convert values in calc column (which are lists) to string\n",
    "    # Doing this makes it possible to obtain unique values from this column\n",
    "    reduced = reduced.astype(str)\n",
    "    reduced = reduced.unique().tolist()\n",
    "    \n",
    "    # Append unique values found to bin_cols\n",
    "    bin_cols.append(reduced)\n",
    "\n",
    "\n",
    "# Loop through bin_cols values which are strings\n",
    "# The goal is to split the strings into a list, \n",
    "# and only obtain unique single elements\n",
    "for i,v in enumerate(bin_cols):\n",
    "   \n",
    "    # Remove any uneeded chars to obtain only values\n",
    "    bin_cols[i] = normalize_text(v)\n",
    "    \n",
    "    # Split result to list by space and obtain unique values.\n",
    "    # The normalization of text ensures text that had spaces was replaced with hyphens\n",
    "    bin_cols[i] = bin_cols[i].split(\" \")\n",
    "    \n",
    "    # convert to series to obtain unique elements easily\n",
    "    bin_cols[i] = pd.Series(bin_cols[i])\n",
    "    bin_cols[i] = bin_cols[i].unique()\n",
    "    \n",
    "    # append current field_name and unique count to field_map\n",
    "    # which will be used as an index table to keep values together with what field they came from\n",
    "    field_name = calculated_fields[i]\n",
    "    val_count = len(bin_cols[i])\n",
    "    field_map.append([field_name, val_count])\n",
    "\n",
    "# Flatten bin cols to remove nested lists\n",
    "bin_cols = flatten_list(bin_cols)\n",
    "\n",
    "print(bin_cols[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Field Name  Unique Count  Index Start  Index End\n",
      "0      CALC_BusinessParking_Options             5            0          4\n",
      "1          CALC_GoodForMeal_Options             6            5         10\n",
      "2                CALC_Music_Options             6           11         16\n",
      "3           CALC_BestNights_Options             7           17         23\n",
      "4             CALC_Ambience_Options             9           24         32\n",
      "5  CALC_DietaryRestrictions_Options             6           33         38\n",
      "6    CALC_HairSpecializesIn_Options             8           39         46\n",
      "7                     CALC_DaysOpen             7           47         53\n",
      "8                   CALC_Categories          1301           54       1354\n",
      "9                     CALC_Location          1126         1355       2480\n"
     ]
    }
   ],
   "source": [
    "# The following script will create the index start and end columns for the map table.\n",
    "# This makes it easy to obtain slices of the bin_cols list which creating the bool results below.\n",
    "field_map = pd.DataFrame(field_map, columns=[\"Field Name\", \"Unique Count\"])\n",
    "\n",
    "#defaults\n",
    "start_at = 0\n",
    "end_at = 0\n",
    "result = []\n",
    "\n",
    "for i,v in field_map[\"Unique Count\"].items():\n",
    "    if(end_at == 0):\n",
    "        end_at = v - 1\n",
    "    else:\n",
    "        start_at = end_at + 1\n",
    "        end_at = v + start_at - 1\n",
    "    result.append([start_at, end_at])\n",
    "\n",
    "result = pd.DataFrame(result, columns=[\"Index Start\",\"Index End\"])\n",
    "field_map = pd.concat([field_map, result], axis=1)\n",
    "print(field_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bin matrix and save to csv file for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *This script may take serveral minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data = []\n",
    "\n",
    "# loop through rows in calculated fields\n",
    "for i,row in df_calc_fields.iterrows():\n",
    "    \n",
    "    # Stores bool results from checking if features exist for current item\n",
    "    bools = []\n",
    "    \n",
    "    # Loop through each field_name and value in current row.\n",
    "    for k,v in row.items():   \n",
    "        # Finds current row in field map\n",
    "        which_field = field_map[\"Field Name\"] == k\n",
    "        \n",
    "        # Get start and end cords for slicing the bin_cols list\n",
    "        start = int(field_map[\"Index Start\"][which_field])\n",
    "        end = int(field_map[\"Index End\"][which_field]) + 1\n",
    "        \n",
    "        # Slice bin cols list\n",
    "        # This contains the list of boolean features to look for in the current field\n",
    "        feat_values = bin_cols[start:end]\n",
    "        \n",
    "        # Make sure current value is a list\n",
    "        if(isinstance(v, list) and len(v)>0):\n",
    "            \n",
    "            # Series created to utilize the isin method\n",
    "            tmp_series = pd.Series(feat_values)\n",
    "            \n",
    "            # Normalize text before running the bool checks\n",
    "            norm_vals = list(map(normalize_text, v))\n",
    "            \n",
    "            # Bool check for features in current field\n",
    "            bool_result = tmp_series.isin(norm_vals).tolist()\n",
    "           \n",
    "           \n",
    "            bools.append(bool_result)\n",
    "            \n",
    "        else:\n",
    "            #if not a list then append all false values\n",
    "            bools.append([False]*len(feat_values))\n",
    "    \n",
    "    # Flatten bools to treat all checks as a single row \n",
    "    bools = flatten_list(bools)\n",
    "    # Append row for the bin matrix\n",
    "    bin_data.append(bools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677\n"
     ]
    }
   ],
   "source": [
    "# Convert bin matrix to data frame and transform True/False to 1/0\n",
    "df_bin_data = pd.DataFrame(bin_data, columns=bin_cols)\n",
    "df_bin_data = df_bin_data.astype(int)\n",
    "\n",
    "# Drop features that have less than 3 business that contain their value's\n",
    "# This is to reduce the column size as well as to remove features that don't add much to the model\n",
    "bin_data_col_sums = df_bin_data.sum(axis=0)\n",
    "which_field = bin_data_col_sums < 3\n",
    "drop_index = bin_data_col_sums[which_field].index.tolist()\n",
    "\n",
    "df_bin_data = df_bin_data.drop(drop_index, axis=1)\n",
    "\n",
    "# Amount of columns to drop\n",
    "print(len(drop_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 192609 entries, 0 to 192608\n",
      "Columns: 1804 entries, lot to litchfield-az\n",
      "dtypes: int32(1804)\n",
      "memory usage: 1.3 GB\n"
     ]
    }
   ],
   "source": [
    "df_bin_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192609, 1805)\n"
     ]
    }
   ],
   "source": [
    "# Insert business id to label each row\n",
    "df_bin_data.insert (0, \"business_id\", business_df[\"business_id\"])\n",
    "\n",
    "\n",
    "print(df_bin_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>lot</th>\n",
       "      <th>garage</th>\n",
       "      <th>valet</th>\n",
       "      <th>street</th>\n",
       "      <th>validated</th>\n",
       "      <th>lunch</th>\n",
       "      <th>dinner</th>\n",
       "      <th>brunch</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>...</th>\n",
       "      <th>oberlin-oh</th>\n",
       "      <th>pheonix-az</th>\n",
       "      <th>cuyahoga-fls-oh</th>\n",
       "      <th>walton-hills-oh</th>\n",
       "      <th>highland-hills-oh</th>\n",
       "      <th>tottenham-on</th>\n",
       "      <th>fairport-harbor-oh</th>\n",
       "      <th>russellton-pa</th>\n",
       "      <th>mcadenville-nc</th>\n",
       "      <th>litchfield-az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>--7zmmkVg-IMGaXbuVd0SQ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>--8LPVSo5i0Oo61X01sV9A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>--9QQLMTbFzLJ_oT-ON3Xw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1805 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  lot  garage  valet  street  validated  lunch  \\\n",
       "0  --1UhMGODdWsrMastO9DZw    0       0      0       0          0      0   \n",
       "1  --6MefnULPED_I942VcFNA    1       0      0       0          0      1   \n",
       "2  --7zmmkVg-IMGaXbuVd0SQ    1       0      0       0          0      0   \n",
       "3  --8LPVSo5i0Oo61X01sV9A    0       0      0       0          0      0   \n",
       "4  --9QQLMTbFzLJ_oT-ON3Xw    0       0      0       0          0      0   \n",
       "\n",
       "   dinner  brunch  breakfast  ...  oberlin-oh  pheonix-az  cuyahoga-fls-oh  \\\n",
       "0       0       0          0  ...           0           0                0   \n",
       "1       1       0          0  ...           0           0                0   \n",
       "2       0       0          0  ...           0           0                0   \n",
       "3       0       0          0  ...           0           0                0   \n",
       "4       0       0          0  ...           0           0                0   \n",
       "\n",
       "   walton-hills-oh  highland-hills-oh  tottenham-on  fairport-harbor-oh  \\\n",
       "0                0                  0             0                   0   \n",
       "1                0                  0             0                   0   \n",
       "2                0                  0             0                   0   \n",
       "3                0                  0             0                   0   \n",
       "4                0                  0             0                   0   \n",
       "\n",
       "   russellton-pa  mcadenville-nc  litchfield-az  \n",
       "0              0               0              0  \n",
       "1              0               0              0  \n",
       "2              0               0              0  \n",
       "3              0               0              0  \n",
       "4              0               0              0  \n",
       "\n",
       "[5 rows x 1805 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bin_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to csv for later use.\n",
    "df_to_csv(df_bin_data, fp + \"/\" + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Up\n",
    "business_df = None\n",
    "df_bin_data = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
