{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation:\n",
    "<p><b><u>Evaluation measures used:</u></b><p>\n",
    "<p>I will be using the F1 Score as the primary measure for performance.</p>\n",
    "<p><b><u>Vector similarity measure:</u></b></p>\n",
    "<p>I will be using the cosine similarity between user vectors and business vectors as a “closeness” measure.  This measure will show how similar a user’s taste is to a specific business.  This measure can take a value between -1 and 1 (with 1 representing a perfect match).\n",
    "Approach:</p>\n",
    "<p>A set of users with a good amount of reviews will be retrieved. These users will have their profiles (vectors) compared to a balanced set of their existing likes and dislikes.</p>\n",
    "<p>A cosine similarity value will then be retrieved for the business vectors in the balanced test set. A cut-off point will be created for each user that will map the cosine similarity to a binary value of 1,-1.  The cut-off point will be the median of all similarity scores obtained for the current user’s balanced test set.  I use the median to ensure I predict half 1s and half -1s.</p>\n",
    "<p>The predicted (mapped) user score of 1,-1 will then be compared to their actual score using a Boolean column of True/False. The TP, FP, TN, TN results will be calculated from the Boolean column and the F1 score will be obtained (for each user).</p>\n",
    "<p>Lastly, the mean of all the F1 scores will be used to show how well this model performs.</p>\n",
    "<p><b><u>Additional info:</u></b></p>\n",
    "<p>The user profile vectors are created with all of the user's likes and dislikes, even if the class is imbalanced (more likes than dislikes).  This is to get a good idea of what the user's taste is based on the businesses they have already liked or disliked. \n",
    "I did not perform a train/test split on the data used to create the user profiles to preserve the information already obtained to build them.  The test will measure how well the full user profile vectors (containing all of the user to business interactions) perform, and can be done on a per user basis to show how well their current model is performing.</p>\n",
    "<p>The test set is a balanced set of user reviews between likes/dislikes.  The balancing is performed with under-sampling the majority class.  The balancing is done to get accurate test results on the models, and to prevent high accuracy scores due to one class outcome holding most of the values.\n",
    "The test set can be pictured as new businesses that a user hasn't seen yet, with similar attributes to what they've already liked.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from itertools import chain\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "fp = \"C:/Users/Tolis/Documents/Data Analytics Cource/CKME136 X10/Project/data/final/profiles\"\n",
    "\n",
    "\n",
    "db_settings = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"un\": \"root\",\n",
    "    \"pw\": \"\",\n",
    "    \"db_name\": \"yelp\"\n",
    "}\n",
    "\n",
    "def mysql_result_to_df(myresult, mycursor):\n",
    "    field_names = [i[0] for i in mycursor.description]\n",
    "    return pd.DataFrame(myresult, columns=field_names)\n",
    "\n",
    "def flatten_list(l):\n",
    "    return list(chain.from_iterable(l))\n",
    "\n",
    "\"\"\"\n",
    "    Takes in a user_id (string) and returns all reviews for the user provided.\n",
    "    The user star rating gets converted to a 1,-1 based \n",
    "    on the 'min like threshold of' 3.5.\n",
    "\"\"\"\n",
    "def get_user_reviews(user_id):\n",
    "    mydb = mysql.connector.connect(\n",
    "        host=db_settings[\"host\"],\n",
    "        user=db_settings[\"un\"],\n",
    "        passwd=db_settings[\"pw\"],\n",
    "        database=db_settings[\"db_name\"]\n",
    "    )\n",
    "    \n",
    "    mycursor = mydb.cursor()\n",
    "    \n",
    "    q = f\"\"\"\n",
    "        SELECT review_id, user_id, business_id,\n",
    "        CASE\n",
    "            WHEN stars >= 3.5 THEN 1\n",
    "            ELSE -1\n",
    "        END AS \"like/dislike\"\n",
    "        FROM review WHERE user_id = '{user_id}'\n",
    "        \"\"\"\n",
    "    \n",
    "    mycursor.execute(q)\n",
    "    user_reviews = mycursor.fetchall()\n",
    "    \n",
    "    user_reviews_df = mysql_result_to_df(user_reviews, mycursor)\n",
    "    mycursor.close()\n",
    "    \n",
    "    return user_reviews_df\n",
    "\n",
    "\"\"\"\n",
    "    Takes in a user profile vector and a set of business profile vectors.\n",
    "    The cosign similarity is obtained between the user and business vector(s) and returned as a series.\n",
    "\"\"\"\n",
    "def get_recommendations(user_profile_df, business_profiles, max_amt=None):\n",
    "    #Get the cosine similarity of the user profile vector and each business profile vector passed in\n",
    "    rec_scores = cosine_similarity(user_profile_df.drop(\"user_id\", axis=1), \n",
    "                                              business_profiles.drop(\"business_id\", axis=1))\n",
    "\n",
    "    # Convert scores to series object and set labels equal to business ids\n",
    "    rec_scores = pd.Series(rec_scores[0])\n",
    "    rec_scores.index = business_profiles[\"business_id\"]\n",
    "    rec_scores = rec_scores.sort_values(ascending=False)\n",
    "    if (not(max_amt is None)):\n",
    "        rec_scores = rec_scores.head(max_amt)\n",
    "        \n",
    "    return rec_scores\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Maps the user id string to a user vector, drops columns that aren't needed,\n",
    "    and returns the result.\n",
    "\"\"\"\n",
    "def get_user_profile(user_profiles, user_id_map, user_id):\n",
    "    \n",
    "    result = user_profiles.merge(user_id_map, left_on=\"user_id\", right_on=\"index\")\n",
    "    result = result.drop([\"user_id_x\",\"index\"], axis=1)\n",
    "    result[\"user_id\"] = result[\"user_id_y\"]\n",
    "    result = result.drop([\"user_id_y\"], axis=1)\n",
    "    result = result[ result[\"user_id\"] == user_id ]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "    Takes in the confusion matrix from a test result and obtains metrics for evaluation:\n",
    "    accuracy, recall, precision, f1_score.\n",
    "    \n",
    "    The functions returns the f1_score which is the primary measure.\n",
    "\"\"\"\n",
    "def get_test_scores(conf_matrix):\n",
    "    tp = conf_matrix[\"TP\"]\n",
    "    fp = conf_matrix[\"FP\"]\n",
    "    tn = conf_matrix[\"TN\"]\n",
    "    fn = conf_matrix[\"FN\"]\n",
    "    results = []\n",
    "    \n",
    "    accuracy = (tp+tn)/(tp+fp+tn+fn)\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    f1_score = 2*(recall * precision) / (recall + precision)\n",
    "    \n",
    "    results.append(f1_score)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query database for users that have at least 100 reviews and obtain their review rows.\n",
    "<p>The reason I chose users with 100 reviews is because the model should work better when users have more business interactions, since the user vector profile changes everytime a like/dislike is performed on a business.  Users with enough reviews makes testing easier, and a problem with the model would be more visible during evaluation as opposed to a user with very few interactions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mysql.connector.connect(\n",
    "    host=db_settings[\"host\"],\n",
    "    user=db_settings[\"un\"],\n",
    "    passwd=db_settings[\"pw\"],\n",
    "    database=db_settings[\"db_name\"]\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "q = f\"\"\"\n",
    "    SELECT review_id, user_id, business_id,\n",
    "    CASE\n",
    "        WHEN stars >= 3.5 THEN 1\n",
    "        ELSE -1\n",
    "    END AS \"like/dislike\"\n",
    "    FROM review;\n",
    "    \"\"\"\n",
    "mycursor.execute(q)\n",
    "user_reviews = mycursor.fetchall()\n",
    "\n",
    "user_reviews_df = mysql_result_to_df(user_reviews, mycursor)\n",
    "\n",
    "q = f\"\"\"\n",
    "    SELECT user_id, COUNT(*) FROM review\n",
    "    GROUP BY user_id HAVING COUNT(*)>=100;\n",
    "    \"\"\"\n",
    "mycursor.execute(q)\n",
    "user_counts = mycursor.fetchall()\n",
    "\n",
    "user_counts_df = mysql_result_to_df(user_counts, mycursor)\n",
    "\n",
    "mycursor.close()\n",
    "which_rows = user_reviews_df[\"user_id\"].isin(user_counts_df[\"user_id\"])\n",
    "user_reviews_df_filt = user_reviews_df[which_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a second filter to the data to ensure that the minority class between (1) disike and (-1) like has atleast 40 rows.\n",
    "<p>A previous step shows a left skewed distribution for user star ratings, with most ratings between 3-5. Due to this, I expect a class imbalance mostly with the like count being greater than the dislike count.</p>\n",
    "<p>To address this issue, I will under sample the majority class based on the count of the minority class.  The minimum count for the minority class (40) is to filter out  users with very low dislike counts and to prevent the balanced sample from being to small.</p>\n",
    "<p>Example: If a user has 200 likes but only 4 dislikes, a sample of 4 likes will be taken to balance the likes/dislikes class.  This will leave us with a total of 8 records to test on, which is too small for a good evaluation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min count for minority class\n",
    "count_min = 40\n",
    "\n",
    "# Get a count of users likes and dislikes to identity the minory class\n",
    "user_reviews_df_grouped = user_reviews_df_filt.groupby([\"user_id\",\"like/dislike\"], as_index=False).count()\n",
    "\n",
    "# Get the unique ids for each user with atleast 100 reavies\n",
    "user_review_ids = pd.Series(user_reviews_df_grouped[\"user_id\"].unique().tolist())\n",
    "\n",
    "def filter_reviews(x, df=user_reviews_df_grouped, count_min=count_min):\n",
    "    # Find row in grouped dataframe (by user_id and like/dislike)\n",
    "    which_row = df[\"user_id\"] == x\n",
    "    current = df[which_row]\n",
    "    \n",
    "    # Check if the min count (minority class) between like or dislike \n",
    "    return current[\"review_id\"].min() >= count_min\n",
    "    \n",
    "user_review_ids = user_review_ids[user_review_ids.apply(filter_reviews)]\n",
    "user_review_ids.shape\n",
    "#user_id=\"-P3SyBLmBhyhDcYatlBgBQ\"\n",
    "#def user_reviews_df_grouped(row)\n",
    "#user_reviews_df_grouped.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single user evaluation:\n",
    "<p>I will perform the evaluation steps on a single user first to outline the process to obtain the F1 score.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balance like/dislike class\n",
    "<p>I will use the balanced class result as the test set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take first id in filtered list \n",
    "user_id = user_review_ids[0]\n",
    "\n",
    "#Get current reviews for user\n",
    "top_user_reviews = get_user_reviews(user_id)\n",
    "\n",
    "#Filter reviews between likes and dislikes.\n",
    "top_user_reviews_dislikes = top_user_reviews[ top_user_reviews[\"like/dislike\"] == -1]\n",
    "top_user_reviews_likes = top_user_reviews[ top_user_reviews[\"like/dislike\"] == 1 ]\n",
    "\n",
    "# If dislike count is minority class, use it's count as the under sample amount.\n",
    "# Otherwise, use the like count.\n",
    "if(top_user_reviews_dislikes.shape[0]<top_user_reviews_likes.shape[0]):\n",
    "    s_size = top_user_reviews_dislikes.shape[0]\n",
    "else:\n",
    "    s_size = top_user_reviews_likes.shape[0]\n",
    "\n",
    "# Obtain samples with the minority class count.\n",
    "# Note: one of these dataframes will have all of their rows returned (minority class)\n",
    "# The majority class will be the only one sampled\n",
    "top_user_reviews_dislikes = top_user_reviews_dislikes.sample(n=s_size)\n",
    "top_user_reviews_likes = top_user_reviews_likes.sample(n=s_size)\n",
    "\n",
    "#Combine balanced classes to one dataframe and use as test set\n",
    "top_user_reviews_balanced = pd.concat([top_user_reviews_likes,top_user_reviews_dislikes], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview balanced class count for current test user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "like/dislike\n",
       "-1    66\n",
       " 1    66\n",
       "Name: business_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_user_reviews_balanced.groupby(\"like/dislike\").count()[\"business_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get user profile for current test user\n",
    "<p>The profile was constructed in previous steps utilizing all of the user's likes/dislikes</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lot</th>\n",
       "      <th>garage</th>\n",
       "      <th>valet</th>\n",
       "      <th>street</th>\n",
       "      <th>validated</th>\n",
       "      <th>lunch</th>\n",
       "      <th>dinner</th>\n",
       "      <th>brunch</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>dessert</th>\n",
       "      <th>...</th>\n",
       "      <th>matchmakers</th>\n",
       "      <th>badminton</th>\n",
       "      <th>perfume</th>\n",
       "      <th>themed-cafes</th>\n",
       "      <th>misting-system-services</th>\n",
       "      <th>cideries</th>\n",
       "      <th>bike-tours</th>\n",
       "      <th>private-schools</th>\n",
       "      <th>drive-in-theater</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1979</td>\n",
       "      <td>0.197248</td>\n",
       "      <td>-0.159493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690468</td>\n",
       "      <td>-0.208199</td>\n",
       "      <td>0.51492</td>\n",
       "      <td>0.705978</td>\n",
       "      <td>0.168132</td>\n",
       "      <td>0.176434</td>\n",
       "      <td>0.514746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-P3SyBLmBhyhDcYatlBgBQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lot    garage  valet    street  validated    lunch    dinner  \\\n",
       "1979  0.197248 -0.159493    0.0  0.690468  -0.208199  0.51492  0.705978   \n",
       "\n",
       "        brunch  breakfast   dessert  ...  matchmakers  badminton  perfume  \\\n",
       "1979  0.168132   0.176434  0.514746  ...          0.0        0.0      0.0   \n",
       "\n",
       "      themed-cafes  misting-system-services  cideries  bike-tours  \\\n",
       "1979           0.0                      0.0       0.0         0.0   \n",
       "\n",
       "      private-schools  drive-in-theater                 user_id  \n",
       "1979              0.0               0.0  -P3SyBLmBhyhDcYatlBgBQ  \n",
       "\n",
       "[1 rows x 1130 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_map = pd.read_parquet(fp+\"/user_id_map.gzip\")\n",
    "user_profiles = pd.read_parquet(fp+\"/user_profile_weighted.gzip\")\n",
    "user_profiles_filt = get_user_profile(user_profiles, user_id_map, user_id)\n",
    "user_profiles_filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain the business profile vectors for the balanced test set\n",
    "<p>First, all business profiles are opened, then filtered by the balanced set's business ids</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_profiles_weighted = pd.read_parquet(fp+\"/business_profiles_weighted.gzip\")\n",
    "test_ids = business_profiles_weighted[\"business_id\"].isin(top_user_reviews_balanced[\"business_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get recommendation scores for current user profile vector and business vectors from the balanced set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_scores = get_recommendations(user_profiles_filt, business_profiles_weighted[test_ids])\n",
    "rec_scores = rec_scores.reset_index()\n",
    "# Join in actual review data for user to obtain TP, FP, TN, FN count.\n",
    "rec_scores = top_user_reviews_balanced.merge(rec_scores, on=\"business_id\")\n",
    "rec_scores.columns = top_user_reviews_balanced.columns.tolist() + [\"rec_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map the cosine similarity value to either +1 or -1\n",
    "<p>I use the median value for all recommendation scores obtained as the cut-off point for a +1 or -1.  I did this to ensure that an even number of 1s and -1s are obtained from the recommendation score.  For example, making the cut-off value higher than the median will cause most rec_scores to be less than that amount, causing -1s to be returned most of the time.  Since we are testing on a balanced class of likes/dislikes, the model shouldn't overpredict only one class outcome.</p>\n",
    "<p>*Note: The recommendation score median will be different for each user's results and will fluctuate depending on the results obtained from the balanced class sample</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_median = score_median=rec_scores[\"rec_score\"].median()\n",
    "def get_pred_score(row, cutoff):\n",
    "    if(row[\"rec_score\"]>=cutoff):\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "rec_scores[\"pred\"] = rec_scores.apply(get_pred_score, axis=1, args=(score_median,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the count of predictions made\n",
    "<p>The distribution should be 50% for each class outcome.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred\n",
       "-1    65\n",
       " 1    67\n",
       "Name: rec_score, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_scores.groupby(\"pred\").count()[\"rec_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create comparison column that checks if the predicted outcome matches the actual outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_scores[\"is_equal\"] = rec_scores.apply(lambda row: row[\"like/dislike\"] == row[\"pred\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use boolean comparison field created above + the actual and predicted class outcome for a user to get (TP, FP, TN, FN) outcomes.\n",
    "<p>I will group by the obtained test outcomes and get the counts for each one.  This will be the confusion matrix.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>like/dislike</th>\n",
       "      <th>rec_score</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_equal</th>\n",
       "      <th>is_equal_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7lq-KgoGt_rZjG65Sn2-gg</td>\n",
       "      <td>-P3SyBLmBhyhDcYatlBgBQ</td>\n",
       "      <td>qwlsGR-pJb6xMWJBqiNIQw</td>\n",
       "      <td>1</td>\n",
       "      <td>0.209411</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BMI1Ad8Snnu29rH4DL0Oew</td>\n",
       "      <td>-P3SyBLmBhyhDcYatlBgBQ</td>\n",
       "      <td>oDBz4UnpaAVkBFGEAUaQPA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435074</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rZuh0QhZCmB2IxV6yI1fUQ</td>\n",
       "      <td>-P3SyBLmBhyhDcYatlBgBQ</td>\n",
       "      <td>oDBz4UnpaAVkBFGEAUaQPA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435074</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>JfIQIv2UXypMxR3qjUOrAA</td>\n",
       "      <td>-P3SyBLmBhyhDcYatlBgBQ</td>\n",
       "      <td>oDBz4UnpaAVkBFGEAUaQPA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435074</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rb5wztLkodfzOZa8iDzAgQ</td>\n",
       "      <td>-P3SyBLmBhyhDcYatlBgBQ</td>\n",
       "      <td>oDBz4UnpaAVkBFGEAUaQPA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435074</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  7lq-KgoGt_rZjG65Sn2-gg  -P3SyBLmBhyhDcYatlBgBQ  qwlsGR-pJb6xMWJBqiNIQw   \n",
       "1  BMI1Ad8Snnu29rH4DL0Oew  -P3SyBLmBhyhDcYatlBgBQ  oDBz4UnpaAVkBFGEAUaQPA   \n",
       "2  rZuh0QhZCmB2IxV6yI1fUQ  -P3SyBLmBhyhDcYatlBgBQ  oDBz4UnpaAVkBFGEAUaQPA   \n",
       "3  JfIQIv2UXypMxR3qjUOrAA  -P3SyBLmBhyhDcYatlBgBQ  oDBz4UnpaAVkBFGEAUaQPA   \n",
       "4  rb5wztLkodfzOZa8iDzAgQ  -P3SyBLmBhyhDcYatlBgBQ  oDBz4UnpaAVkBFGEAUaQPA   \n",
       "\n",
       "   like/dislike  rec_score  pred  is_equal is_equal_type  \n",
       "0             1   0.209411    -1     False            FN  \n",
       "1             1   0.435074     1      True            TP  \n",
       "2             1   0.435074     1      True            TP  \n",
       "3             1   0.435074     1      True            TP  \n",
       "4             1   0.435074     1      True            TP  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_test_cat(row):\n",
    "    if(row[\"is_equal\"] and row[\"like/dislike\"]==1):\n",
    "        return \"TP\"\n",
    "    elif(row[\"is_equal\"] and row[\"like/dislike\"]==-1):\n",
    "        return \"TN\"\n",
    "    elif( not(row[\"is_equal\"]) and row[\"like/dislike\"]==1):\n",
    "        return \"FN\"\n",
    "    else:\n",
    "        return \"FP\"\n",
    "rec_scores[\"is_equal_type\"] = rec_scores.apply(get_test_cat, axis=1)\n",
    "rec_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create confusion matrix from test results and calculate F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_equal_type\n",
       "FN    20\n",
       "FP    21\n",
       "TN    45\n",
       "TP    46\n",
       "Name: is_equal, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = rec_scores.groupby(\"is_equal_type\").count()[\"is_equal\"]\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Id:  -P3SyBLmBhyhDcYatlBgBQ \n",
      "F1 Score: 0.6917293233082707\n"
     ]
    }
   ],
   "source": [
    "results = get_test_scores(conf_matrix)\n",
    "print(\"User Id: \", user_id, \"\\nF1 Score:\", results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple user evaluation:\n",
    "<p>The same steps as the single user evaluation will be performed for all users obtained in the filtered set.  I will take the average of all F1 scores obtained as the primary metric for how well this model performs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "# Will store each user's evaluation metrics\n",
    "evaluation_results = []\n",
    "\n",
    "\n",
    "for i,v in enumerate(user_review_ids):\n",
    "    user_id = v\n",
    "    \n",
    "    # Get current user's reviews and seperate to two datasets:\n",
    "    # One for likes, one for dislikes...\n",
    "    curr_user_reviews = get_user_reviews(user_id)\n",
    "    curr_user_reviews_dislikes = curr_user_reviews[ curr_user_reviews[\"like/dislike\"] == -1]\n",
    "    curr_user_reviews_likes = curr_user_reviews[ curr_user_reviews[\"like/dislike\"] == 1 ]\n",
    "    \n",
    "    # Get row counts for like and dislike data\n",
    "    dislikes_count = curr_user_reviews_dislikes.shape[0]\n",
    "    likes_count = curr_user_reviews_likes.shape[0]\n",
    "    \n",
    "    # Find the smaller row count for the likes, dislikes data and make that the under sample size.\n",
    "    if(dislikes_count<likes_count):\n",
    "        s_size = curr_user_reviews_dislikes.shape[0]\n",
    "    else:\n",
    "        s_size = curr_user_reviews_likes.shape[0]\n",
    "        \n",
    "    # Sample like, dislike data using smaller row count as amount\n",
    "    # This is to balance the class...\n",
    "    curr_user_reviews_dislikes = curr_user_reviews_dislikes.sample(n=s_size)\n",
    "    curr_user_reviews_likes = curr_user_reviews_likes.sample(n=s_size)\n",
    "    \n",
    "    # Skip user if they only have all likes or all dislikes...\n",
    "    if(curr_user_reviews_dislikes.empty or curr_user_reviews_likes.empty):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Create balanced test set for the user\n",
    "    curr_user_reviews_balanced = pd.concat([curr_user_reviews_likes,\n",
    "                                           curr_user_reviews_dislikes], axis=0, ignore_index=True)\n",
    "    \n",
    "    # Get user profile vector for current user\n",
    "    user_profiles_filt = get_user_profile(user_profiles, user_id_map, user_id)\n",
    "    \n",
    "    # Get business profiles using business ids obtained from balanced class\n",
    "    test_ids = business_profiles_weighted[\"business_id\"].isin(curr_user_reviews_balanced[\"business_id\"])\n",
    "    \n",
    "    # Get rec scores for current user and balanced test set\n",
    "    rec_scores = get_recommendations(user_profiles_filt, business_profiles_weighted[test_ids])\n",
    "    rec_scores = rec_scores.reset_index()\n",
    "    rec_scores = curr_user_reviews_balanced.merge(rec_scores, on=\"business_id\")\n",
    "    rec_scores.columns = curr_user_reviews_balanced.columns.tolist() + [\"rec_score\"] \n",
    "    \n",
    "    # Map scores to either +1, -1 using rec score median as the cut off\n",
    "    score_median = rec_scores[\"rec_score\"].median()\n",
    "    rec_scores[\"pred\"] = rec_scores.apply(get_pred_score, axis=1, args=(score_median,))\n",
    "    \n",
    "    # Check if predicitions are equal to actuals\n",
    "    rec_scores[\"is_equal\"] = rec_scores.apply(lambda row: row[\"like/dislike\"] == row[\"pred\"], axis=1)\n",
    "    \n",
    "    # Map is_equal results to TP, FP, TN, FN\n",
    "    rec_scores[\"is_equal_type\"] = rec_scores.apply(get_test_cat, axis=1)\n",
    "    \n",
    "    # Get confusion matrix for current user and obtain results\n",
    "    conf_matrix = rec_scores.groupby(\"is_equal_type\").count()[\"is_equal\"]\n",
    "    results = get_test_scores(conf_matrix)\n",
    "    \n",
    "    # Append results for current user to list\n",
    "    user_results = [user_id] + results\n",
    "    evaluation_results.append(user_results)\n",
    "    \n",
    "evaluation_results = pd.DataFrame(evaluation_results, columns=[\"user_id\",\"fscore\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview top 20 multi-user evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9pNcdrQLWWrX0vEGGJlEbg</td>\n",
       "      <td>0.893617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>ACwBMSJzgW6vOvV7vOrk8Q</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0Zswwlz4NzUJoG-skyWzIw</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>FgyvflZtqRF03j5bIrlnlA</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3xBFFH866WoySDG7uuwBSQ</td>\n",
       "      <td>0.759494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Ksp1e9Dw0Jcog_ZBD3-45g</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Lk70TsLeGBYSXsnr5q-cXg</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>CxDOIDnH8gp9KXzpBHJYXw</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9-oFF_fYUJEfpm_Gm9fMAQ</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-P3SyBLmBhyhDcYatlBgBQ</td>\n",
       "      <td>0.691729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Fsl7fnXttgugpoyuCJ0zkg</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>ELcQDlf69kb-ihJfxZyL0A</td>\n",
       "      <td>0.679012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>80Vumo-RutgyYMno_2xFwg</td>\n",
       "      <td>0.658537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Ao-6FYE29-I8WwPg67806A</td>\n",
       "      <td>0.644444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8drMKNHWavs2g6uf0pLtvg</td>\n",
       "      <td>0.634615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>MMf0LhEk5tGa1LvN7zcDnA</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>BfKQ_AwlgxBeGP9580eCkQ</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3tCzdXFXke958utEjcSdmg</td>\n",
       "      <td>0.554217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7C4B2Skmh4X9f8xJDo9O4w</td>\n",
       "      <td>0.520548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_id    fscore\n",
       "9   9pNcdrQLWWrX0vEGGJlEbg  0.893617\n",
       "10  ACwBMSJzgW6vOvV7vOrk8Q  0.850000\n",
       "1   0Zswwlz4NzUJoG-skyWzIw  0.846154\n",
       "15  FgyvflZtqRF03j5bIrlnlA  0.804878\n",
       "3   3xBFFH866WoySDG7uuwBSQ  0.759494\n",
       "17  Ksp1e9Dw0Jcog_ZBD3-45g  0.740000\n",
       "4   5CgjjDAic2-FAvCtiHpytA  0.718750\n",
       "18  Lk70TsLeGBYSXsnr5q-cXg  0.710000\n",
       "13  CxDOIDnH8gp9KXzpBHJYXw  0.703704\n",
       "8   9-oFF_fYUJEfpm_Gm9fMAQ  0.700000\n",
       "0   -P3SyBLmBhyhDcYatlBgBQ  0.691729\n",
       "16  Fsl7fnXttgugpoyuCJ0zkg  0.686567\n",
       "14  ELcQDlf69kb-ihJfxZyL0A  0.679012\n",
       "6   80Vumo-RutgyYMno_2xFwg  0.658537\n",
       "11  Ao-6FYE29-I8WwPg67806A  0.644444\n",
       "7   8drMKNHWavs2g6uf0pLtvg  0.634615\n",
       "19  MMf0LhEk5tGa1LvN7zcDnA  0.625000\n",
       "12  BfKQ_AwlgxBeGP9580eCkQ  0.583333\n",
       "2   3tCzdXFXke958utEjcSdmg  0.554217\n",
       "5   7C4B2Skmh4X9f8xJDo9O4w  0.520548"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results.head(20).sort_values(by=[\"fscore\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain mean of all F1 score values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6958174263493548"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results[\"fscore\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
